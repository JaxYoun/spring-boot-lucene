# spring-boot-lucene

## 分词器
1. 再对Doc中的内容构建索引前，需要使用分词器进行分词，分词的目的是为了搜索，分词的主要过程是先分词再过滤。
> 索引构建和搜索使用的分词器必须完全一致。
- 分词：采集到的数据会存储到Doc对象的字段中，分词就是将Doc中字段的value，按一定规则切分成一个个词的过程。
- 过滤：主要包括**去除标点符号、去除停顿词、转小写、次形还原（单复数、时态等还原）**。

IKAnalyzer：
1. 扩展词库：存放用户自定义词库，这些次可以是专有词，或者用户认为应当视为一个整体的词，凡是出现在这个词库中的词，分词时将保留为一整个词。
2. 停顿词库：凡是出现在这个词库中的词，都会被过滤掉。

Lucene文档之字段的数据类型（可以查询内置字段类型）
- 是否分词（Tokenized）：是否对此字段进行切分，若需要在此字段上构建索引，则必须对其切分。
- 是否索引（Indexed）：是否对此字段构建索引，如果需要用它来查询，则必须构建索引。
- 是否存储（Stored）：是否将此字段，以文档对象的字段的形式存储到文档库中，若此字段需要被查询展示，则必须存储。

是否分词和是否索引，影响的是索引逻辑结构。
是否存储，影响的是文旦逻辑结构。